description: Test Longer Sequence

target:
  service: sing
  #name: whitney10
  name: whitney16
  #name: msroctobasicvc@gcr-singularity-octo
  workspace_name: lightyear

environment:
  # registry: reubencr.azurecr.io
  image: amlt-sing/acpt-rocm6.1_ubuntu20.04_py3.9_pytorch2.1.2
  #image: rocm/vllm0.6.3-rocm6.2.3-pytorch2.6-fa2.7-singularity-ib:2.0

  setup:
    - echo "start"

storage:
  vlpdatasets:
    storage_account_name: vlpdatasets
    container_name: data  
  model:
    storage_account_name: projects4jw
    container_name: model
  output:
    storage_account_name: reubenprojects
    container_name: model

code:
  local_dir: ./

search:
  job_template:
    #name: premium-amd-pretrain-col33-step56000-rope-template-1.6M-pooling-{mm_use_spatial_pooling}-seqlen-{max_seq_len}-ft-{tune_vision_tokenizer}-frames-{max_num_frames}-finetune-{max_num_crops}-anyres{img_anyres_strategy}-{tune_vision_tokenizer}-{finetune_eps}-{sft_data}_ise{mm_use_image_start_end}_tse{mm_use_trace_start_end}_tsd{mm_use_trace_speed}_rtpts{remove_static_trace_pts}_qsz{spatial_quant_size}
    #name: premium-amd-pretraining_col34-step42000-rope-template-1.6M-pooling-{mm_use_spatial_pooling}-seqlen-{max_seq_len}-ft-{tune_vision_tokenizer}-frames-{max_num_frames}-finetune-{max_num_crops}-anyres{img_anyres_strategy}-{tune_vision_tokenizer}-{finetune_eps}-{sft_data}_ise{mm_use_image_start_end}_tse{mm_use_trace_start_end}_tsd{mm_use_trace_speed}_rtpts{remove_static_trace_pts}_qsz{spatial_quant_size}
    #name: premium-amd-ablate-row3-col7-step14000-rope-template-1.6M-pooling-{mm_use_spatial_pooling}-seqlen-{max_seq_len}-ft-{tune_vision_tokenizer}-frames-{max_num_frames}-finetune-{max_num_crops}-anyres{img_anyres_strategy}-{tune_vision_tokenizer}-{finetune_eps}-{sft_data}_ise{mm_use_image_start_end}_tse{mm_use_trace_start_end}_tsd{mm_use_trace_speed}_rtpts{remove_static_trace_pts}_qsz{spatial_quant_size}
    #name: run3-premium-amd-ablate-row3-col7-step14000-rope-template-1.6M-pooling-{mm_use_spatial_pooling}-seqlen-{max_seq_len}-ft-{tune_vision_tokenizer}-frames-{max_num_frames}-finetune-{max_num_crops}-anyres{img_anyres_strategy}-{tune_vision_tokenizer}-{finetune_eps}-{sft_data}_ise{mm_use_image_start_end}_tse{mm_use_trace_start_end}_tsd{mm_use_trace_speed}_rtpts{remove_static_trace_pts}_qsz{spatial_quant_size}
    #name: premium-amd-scaling-row1-col4-step42000-rope-template-1.6M-pooling-{mm_use_spatial_pooling}-seqlen-{max_seq_len}-ft-{tune_vision_tokenizer}-frames-{max_num_frames}-finetune-{max_num_crops}-anyres{img_anyres_strategy}-{tune_vision_tokenizer}-{finetune_eps}-{sft_data}_ise{mm_use_image_start_end}_tse{mm_use_trace_start_end}_tsd{mm_use_trace_speed}_rtpts{remove_static_trace_pts}_qsz{spatial_quant_size}
    name: long-context-test
    sku: 1xG8-MI300X-IB-xGMI
    #sku: 8xG8-MI300X-IB-xGMI
    #sku: 8x192G8-MI300X-IB-xGMI@westcentralus
    mpi: False
    process_count_per_node: 1
    #sla_tier: Basic
    #sla_tier: Standard
    identity: managed
    command:
      - sleep 100d
    submit_args:
      container_args:
        # shm_size: 256g
        SHARED_MEMORY_PERCENT: 0.8
      env:
        _AZUREML_SINGULARITY_JOB_UAI: /subscriptions/2cd190bb-b42a-477c-b1bb-2f20932d8dc5/resourcegroups/chehao/providers/Microsoft.ManagedIdentity/userAssignedIdentities/lightleap
        NCCL_IB_DISABLE: 0
        NCCL_DEBUG: INFO
        NCCL_IB_TIMEOUT: 60
        MKL_THREADING_LAYER: GNU
    tags: [Project_Name:Cost-Effective_Multimodal_Agentic_Foundation_Models_for_Digital_and_Physical_Worlds,ProjectID:PRJ-0441-A24,Experiment:Video_magma_finetuning]       
  max_trials: 36
  type: grid
  params:
    - name: nnodes
      spec: discrete
      values: [
        8
        #4
      ]    
    - name: llm_model
      spec: discrete
      values: [
        #magma/checkpoints/pt-Qwen/Qwen2.5-0.5B-Instruct-all-bs4-ep3-bimsz512-ncrops4-anyrescrop-seqlen4096-4e-05-cosine-0.0_openx_magma_trace_coin_ego4d_sthv2_epic_seeclick_magma_sharegpt4v_10M_iseTrue_ihTrue_tseFalse_tsdTrue_rtptsTrue_somtomTrue_qsz100-nnodes8/checkpoint-42000
        #magma/checkpoints_copy/data_scaling_row3_col7/checkpoint-16000
        #magma/checkpoints_copy/data_scaling_row3_col7/checkpoint-11000
        #magma/checkpoints_copy/data_scaling_row3_col3/checkpoint-51000
        #magma/checkpoints_copy/data_scaling_row3_col3/checkpoint-43000
        #magma/checkpoints_copy/data_scaling_row3_col3/checkpoint-22000
        #magma/checkpoints_copy/pretraining_col34/checkpoint-42000
        #magma/checkpoints_copy/data_scaling_row2_col3/checkpoint-28000
        #magma/checkpoints_copy/data_scaling_row1_col4/checkpoint-22830
        #magma/checkpoints_copy/finetune-none-bs4-ep3-bimsz512-ncrops4-anyrescrop-seqlen4096-1e-05-constant-0.0_coin_howto100m_ego4d_sthv2_epic_seeclick_llava_sharegpt4v_vision2ui_1M_iseTrue_ihTrue_tseFalse_tsdTrue_rtptsTrue_somtomTrue_qsz256-nnodes8-llama3-8B/checkpoint-15000
        #magma/checkpoints_copy/finetune-none-bs8-ep3-bimsz512-ncrops4-anyrescrop-seqlen3072-1e-5-constant-0.0_openx_magma_trace_coin_howto100m_ego4d_sthv2_epic_seeclick_llava_sharegpt4v_vision2ui_-1_iseTrue_ihTrue_tseFalse_tsdTrue_rtptsTrue_somtomTrue_qsz256-nnodes5/checkpoint-56000
        #magma/checkpoints/finetune-none-bs8-ep3-bimsz512-ncrops4-anyrescrop-seqlen3072-1e-5-constant-0.0_openx_magma_trace_coin_howto100m_ego4d_sthv2_epic_seeclick_llava_sharegpt4v_vision2ui_-1_iseTrue_ihTrue_tseFalse_tsdTrue_rtptsTrue_somtomTrue_qsz256-nnodes5/checkpoint-56000
        #magma/checkpoints/finetune-all-bs8-ep1-bimsz512-ncrops4-anyrescrop-seqlen3072-1e-5-cosine-0.0_openx_magma_trace_coin_howto100m_ego4d_sthv2_epic_seeclick_llava_sharegpt4v_vision2ui_-1_iseTrue_ihTrue_tseFalse_tsdTrue_rtptsTrue_qsz256-nnodes10-zero1
        #magma/checkpoints/finetune-all-bs8-ep1-bimsz512-ncrops4-anyrescrop-seqlen3072-1e-5-cosine-0.0_openx_magma_trace_coin_howto100m_ego4d_sthv2_epic_seeclick_llava_sharegpt4v_vision2ui_-1_iseTrue_ihTrue_tseFalse_tsdTrue_rtptsTrue_qsz256-nnodes10-zero1/
        magma/checkpoints_copy/magma-llama-3-8b-instruct-hf/
      ]
    - name: sft_data
      spec: discrete
      values: [
        #'llava1.5'
        'video_instruction_tuning_cluster'
      ]
    - name: training_size
      spec: discrete
      values: [
        -1
      ]
    - name: base_img_size
      spec: discrete
      values: [
        256
        #512
      ]
    - name: max_num_frames
      spec: discrete
      values: [
        #12
        #16
        32
        #48
        #64
        #96
        #128 
        #256
      ]
    - name: max_num_crops
      spec: discrete
      values: [
        # each crop produces 64 tokens
        #1
        4, 
        # 6,
        #4, 
        # 16,
        # 25, 
        # 36
      ]
    - name: img_anyres_strategy
      spec: discrete
      values: [
        'crop',
        # 'global'
      ]      
    - name: max_seq_len
      spec: discrete
      values: [
        # 2048,
        # 3072,
        #4096,
        # 5184,
        #6144,
        # 7168,
        #8192
        #12288
        #16384
        20480
      ]      
    - name: tune_vision_tokenizer
      spec: discrete
      values: [
        #'none',
        'all',
      ]
    - name: ft_per_gpu_bs
      spec: discrete
      values: [
        1
      ]
    - name: accum_steps
      spec: discrete
      values: [
        #2
        4
      ]
    - name: finetune_eps
      spec: discrete
      values: [
        1
        # 4,
        # 8,
      ]
    - name: lr
      spec: discrete
      values: [
        1e-5,
      ]
    - name: wdecay
      spec: discrete
      values: [
        0.0000,
      ]      
    - name: mm_use_trace_start_end
      spec: discrete
      values: [
        False, 
        # True
      ]
    - name: mm_use_trace_speed
      spec: discrete
      values: [
        False, 
        # True
      ]
    - name: mm_use_image_start_end
      spec: discrete
      values: [
        #False, 
        True
      ]      
    - name: remove_static_trace_pts
      spec: discrete
      values: [
        False
        # True
      ]
    - name: mm_use_spatial_pooling
      spec: discrete
      values: [
        False, 
        #True
      ] 
    - name: spatial_quant_size
      spec: discrete
      values: [
        # 512,
        256, 
        # 128
      ]
    - name: lr_scheduler
      spec: discrete
      values: [
        'cosine',
        # 'cosine_with_min_lr', 
        # 'constant'
      ]